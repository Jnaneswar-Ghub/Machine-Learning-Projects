{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "from seaborn import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>43259079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>43957899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>96632426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-11</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>107632465.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close       Volume\n",
       "0  2020-10-07  0.002610  0.002613  0.002586  0.002600   0.002600   43259079.0\n",
       "1  2020-10-08  0.002598  0.002633  0.002573  0.002603   0.002603   43957899.0\n",
       "2  2020-10-09       NaN       NaN       NaN       NaN        NaN          NaN\n",
       "3  2020-10-10  0.002654  0.002716  0.002654  0.002655   0.002655   96632426.0\n",
       "4  2020-10-11  0.002667  0.002706  0.002649  0.002674   0.002674  107632465.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/DOGE-USD.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 366 entries, 0 to 365\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       366 non-null    object \n",
      " 1   Open       363 non-null    float64\n",
      " 2   High       363 non-null    float64\n",
      " 3   Low        363 non-null    float64\n",
      " 4   Close      363 non-null    float64\n",
      " 5   Adj Close  363 non-null    float64\n",
      " 6   Volume     363 non-null    float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 20.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 363 entries, 0 to 365\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       363 non-null    object \n",
      " 1   Open       363 non-null    float64\n",
      " 2   High       363 non-null    float64\n",
      " 3   Low        363 non-null    float64\n",
      " 4   Close      363 non-null    float64\n",
      " 5   Adj Close  363 non-null    float64\n",
      " 6   Volume     363 non-null    float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 22.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close')\n",
    "plt.plot(data['Close'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred frequency is: D\n",
      "Old data dropped by `drop_data_older_than_periods`.\n",
      "Model Number: 1 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 3 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 4 with model DatepartRegression in generation 0 of 10\n",
      "Model Number: 5 with model DatepartRegression in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 6 with model DatepartRegression in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 7 with model DatepartRegression in generation 0 of 10\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 7s 8ms/step - loss: 0.3568\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3532\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3547\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3471\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3507\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3499\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3510\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3507\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3470\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3464\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3504\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3430\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3446\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3386\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3406\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3392\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3376\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3415\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3367\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3264\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3337\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3323\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3230\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3272\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3331\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3211\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3187\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3097\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3031\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3104\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3024\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2957\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3058\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2951\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2901\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2920\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2959\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2924\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2963\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2846\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2919\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2850\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.275 - 0s 14ms/step - loss: 0.2855\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2945\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2821\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2827\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2757\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2833\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2807\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2816\n",
      "Model Number: 8 with model ETS in generation 0 of 10\n",
      "Model Number: 9 with model ETS in generation 0 of 10\n",
      "Model Number: 10 with model GLM in generation 0 of 10\n",
      "Model Number: 11 with model GLM in generation 0 of 10\n",
      "Model Number: 12 with model GLS in generation 0 of 10\n",
      "Model Number: 13 with model GLS in generation 0 of 10\n",
      "Model Number: 14 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 14: GluonTS\n",
      "Model Number: 15 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 15: GluonTS\n",
      "Model Number: 16 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 16: GluonTS\n",
      "Model Number: 17 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 17: GluonTS\n",
      "Model Number: 18 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 18: GluonTS\n",
      "Model Number: 19 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 19: GluonTS\n",
      "Model Number: 20 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 21 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 22 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 24 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 25 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 26 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 27 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 28 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 29 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 30 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 31 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31: VAR\n",
      "Model Number: 32 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 32: VAR\n",
      "Model Number: 33 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 33: VAR\n",
      "Model Number: 34 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 34: VECM\n",
      "Model Number: 35 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 35: VECM\n",
      "Model Number: 36 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 36: VECM\n",
      "Model Number: 37 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 37: VECM\n",
      "Model Number: 38 with model WindowRegression in generation 0 of 10\n",
      "Model Number: 39 with model ZeroesNaive in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 40 with model ZeroesNaive in generation 0 of 10\n",
      "Model Number: 41 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 42 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 43 with model GLS in generation 0 of 10\n",
      "Model Number: 44 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 45 with model GLM in generation 0 of 10\n",
      "Model Number: 46 with model ETS in generation 0 of 10\n",
      "Model Number: 47 with model FBProphet in generation 0 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 47: FBProphet\n",
      "Model Number: 48 with model RollingRegression in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 49 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 49: GluonTS\n",
      "Model Number: 50 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 51 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 51: VAR\n",
      "Model Number: 52 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 52: VECM\n",
      "Model Number: 53 with model WindowRegression in generation 0 of 10\n",
      "Template Eval Error: UFuncTypeError(<ufunc 'multiply'>, 'same_kind', dtype('float64'), dtype('int32'), 2) in model 53: WindowRegression\n",
      "Model Number: 54 with model DatepartRegression in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 55 with model UnivariateRegression in generation 0 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 55: UnivariateRegression\n",
      "Model Number: 56 with model UnivariateMotif in generation 0 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 56: UnivariateMotif\n",
      "Model Number: 57 with model FBProphet in generation 0 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 57: FBProphet\n",
      "Model Number: 58 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 58: VECM\n",
      "Model Number: 59 with model FBProphet in generation 0 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 59: FBProphet\n",
      "Model Number: 60 with model ETS in generation 0 of 10\n",
      "Model Number: 61 with model RollingRegression in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 62 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 63 with model GLM in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:978: RuntimeWarning: All-NaN slice encountered\n",
      "  max_abs = np.nanmax(np.abs(X), axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Length mismatch: Expected axis has 191 elements, new values have 1 elements') in model 63: GLM\n",
      "Model Number: 64 with model ETS in generation 0 of 10\n",
      "Model Number: 65 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 65: VECM\n",
      "Model Number: 66 with model GLM in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:278: DomainWarning: The inverse_power link function does not respect the domain of the Gamma family.\n",
      "  DomainWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 67 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('zero-size array to reduction operation maximum which has no identity') in model 67: VAR\n",
      "Model Number: 68 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 68: VAR\n",
      "Model Number: 69 with model DatepartRegression in generation 0 of 10\n",
      "Model Number: 70 with model UnivariateRegression in generation 0 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 70: UnivariateRegression\n",
      "Model Number: 71 with model UnivariateRegression in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2995: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 71: UnivariateRegression\n",
      "Model Number: 72 with model UnivariateRegression in generation 0 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 72: UnivariateRegression\n",
      "Model Number: 73 with model RollingRegression in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 74 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 74: VAR\n",
      "Model Number: 75 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 76 with model UnivariateMotif in generation 0 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 76: UnivariateMotif\n",
      "Model Number: 77 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 77: GluonTS\n",
      "Model Number: 78 with model GLS in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2995: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 79 with model RollingRegression in generation 0 of 10\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 79: RollingRegression\n",
      "Model Number: 80 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 81 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 82 with model ETS in generation 0 of 10\n",
      "Model Number: 83 with model GLS in generation 0 of 10\n",
      "Model Number: 84 with model RollingRegression in generation 0 of 10\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 84: RollingRegression\n",
      "Model Number: 85 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 86 with model GLS in generation 0 of 10\n",
      "Template Eval Error: UFuncTypeError(<ufunc 'multiply'>, 'same_kind', dtype('float64'), dtype('int32'), 2) in model 86: GLS\n",
      "Model Number: 87 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 87: VECM\n",
      "Model Number: 88 with model UnivariateRegression in generation 0 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 88: UnivariateRegression\n",
      "Model Number: 89 with model UnivariateMotif in generation 0 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 89: UnivariateMotif\n",
      "Model Number: 90 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 90: GluonTS\n",
      "Model Number: 91 with model ETS in generation 0 of 10\n",
      "Model Number: 92 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 92: VECM\n",
      "Model Number: 93 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 93: VECM\n",
      "Model Number: 94 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 94: VAR\n",
      "Model Number: 95 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 96 with model GLM in generation 0 of 10\n",
      "Model Number: 97 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 97: VECM\n",
      "Model Number: 98 with model ETS in generation 0 of 10\n",
      "Model Number: 99 with model UnivariateMotif in generation 0 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 99: UnivariateMotif\n",
      "Model Number: 100 with model ETS in generation 0 of 10\n",
      "Model Number: 101 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 102 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 102: VAR\n",
      "Model Number: 103 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 104 with model WindowRegression in generation 0 of 10\n",
      "Model Number: 105 with model GLM in generation 0 of 10\n",
      "Model Number: 106 with model GLS in generation 0 of 10\n",
      "Model Number: 107 with model GLS in generation 0 of 10\n",
      "New Generation: 1 of 10\n",
      "Model Number: 108 with model LastValueNaive in generation 1 of 10\n",
      "Model Number: 109 with model LastValueNaive in generation 1 of 10\n",
      "Model Number: 110 with model ETS in generation 1 of 10\n",
      "Model Number: 111 with model ETS in generation 1 of 10\n",
      "Model Number: 112 with model ETS in generation 1 of 10\n",
      "Model Number: 113 with model ETS in generation 1 of 10\n",
      "Model Number: 114 with model RollingRegression in generation 1 of 10\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 114: RollingRegression\n",
      "Model Number: 115 with model RollingRegression in generation 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 116 with model RollingRegression in generation 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 117 with model RollingRegression in generation 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 118 with model AverageValueNaive in generation 1 of 10\n",
      "Model Number: 119 with model AverageValueNaive in generation 1 of 10\n",
      "Model Number: 120 with model AverageValueNaive in generation 1 of 10\n",
      "Model Number: 121 with model SeasonalNaive in generation 1 of 10\n",
      "Model Number: 122 with model SeasonalNaive in generation 1 of 10\n",
      "Model Number: 123 with model SeasonalNaive in generation 1 of 10\n",
      "Model Number: 124 with model SeasonalNaive in generation 1 of 10\n",
      "Model Number: 125 with model ZeroesNaive in generation 1 of 10\n",
      "Model Number: 126 with model ZeroesNaive in generation 1 of 10\n",
      "Model Number: 127 with model ZeroesNaive in generation 1 of 10\n",
      "Model Number: 128 with model UnobservedComponents in generation 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1390: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input, interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: KeyError(Timestamp('2021-03-22 00:00:00', freq='D')) in model 128: UnobservedComponents\n",
      "Model Number: 129 with model UnobservedComponents in generation 1 of 10\n",
      "Model Number: 130 with model UnobservedComponents in generation 1 of 10\n",
      "Model Number: 131 with model WindowRegression in generation 1 of 10\n",
      "Model Number: 132 with model WindowRegression in generation 1 of 10\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 133 with model WindowRegression in generation 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 134 with model GLM in generation 1 of 10\n",
      "Model Number: 135 with model GLM in generation 1 of 10\n",
      "Model Number: 136 with model GLM in generation 1 of 10\n",
      "Model Number: 137 with model GLM in generation 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:893: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 138 with model GLS in generation 1 of 10\n",
      "Model Number: 139 with model GLS in generation 1 of 10\n",
      "Model Number: 140 with model GLS in generation 1 of 10\n",
      "Model Number: 141 with model DatepartRegression in generation 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:1522: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model = self.model.fit(X, y)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 142 with model DatepartRegression in generation 1 of 10\n",
      "Model Number: 143 with model DatepartRegression in generation 1 of 10\n",
      "Model Number: 144 with model GluonTS in generation 1 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 144: GluonTS\n",
      "Model Number: 145 with model GluonTS in generation 1 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 145: GluonTS\n",
      "Model Number: 146 with model GluonTS in generation 1 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 146: GluonTS\n",
      "Model Number: 147 with model GluonTS in generation 1 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 147: GluonTS\n",
      "Model Number: 148 with model VAR in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 148: VAR\n",
      "Model Number: 149 with model VAR in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 149: VAR\n",
      "Model Number: 150 with model VAR in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 150: VAR\n",
      "Model Number: 151 with model VAR in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 151: VAR\n",
      "Model Number: 152 with model VECM in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 152: VECM\n",
      "Model Number: 153 with model VECM in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 153: VECM\n",
      "Model Number: 154 with model VECM in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 154: VECM\n",
      "Model Number: 155 with model VECM in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 155: VECM\n",
      "Model Number: 156 with model FBProphet in generation 1 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 156: FBProphet\n",
      "Model Number: 157 with model FBProphet in generation 1 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 157: FBProphet\n",
      "Model Number: 158 with model FBProphet in generation 1 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 158: FBProphet\n",
      "Model Number: 159 with model FBProphet in generation 1 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 159: FBProphet\n",
      "Model Number: 160 with model UnivariateRegression in generation 1 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 160: UnivariateRegression\n",
      "Model Number: 161 with model UnivariateRegression in generation 1 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 161: UnivariateRegression\n",
      "Model Number: 162 with model UnivariateRegression in generation 1 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 162: UnivariateRegression\n",
      "Model Number: 163 with model UnivariateRegression in generation 1 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 163: UnivariateRegression\n",
      "Model Number: 164 with model UnivariateMotif in generation 1 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 164: UnivariateMotif\n",
      "Model Number: 165 with model UnivariateMotif in generation 1 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 165: UnivariateMotif\n",
      "Model Number: 166 with model UnivariateMotif in generation 1 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 166: UnivariateMotif\n",
      "Model Number: 167 with model UnivariateMotif in generation 1 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 167: UnivariateMotif\n",
      "New Generation: 2 of 10\n",
      "Model Number: 168 with model LastValueNaive in generation 2 of 10\n",
      "Model Number: 169 with model LastValueNaive in generation 2 of 10\n",
      "Model Number: 170 with model ETS in generation 2 of 10\n",
      "Model Number: 171 with model ETS in generation 2 of 10\n",
      "Model Number: 172 with model ETS in generation 2 of 10\n",
      "Model Number: 173 with model ETS in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:744: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 174 with model RollingRegression in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 175 with model RollingRegression in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 176 with model RollingRegression in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 177 with model RollingRegression in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 178 with model AverageValueNaive in generation 2 of 10\n",
      "Model Number: 179 with model AverageValueNaive in generation 2 of 10\n",
      "Model Number: 180 with model AverageValueNaive in generation 2 of 10\n",
      "Model Number: 181 with model SeasonalNaive in generation 2 of 10\n",
      "Model Number: 182 with model SeasonalNaive in generation 2 of 10\n",
      "Model Number: 183 with model SeasonalNaive in generation 2 of 10\n",
      "Model Number: 184 with model SeasonalNaive in generation 2 of 10\n",
      "Model Number: 185 with model UnobservedComponents in generation 2 of 10\n",
      "Model Number: 186 with model UnobservedComponents in generation 2 of 10\n",
      "Model Number: 187 with model UnobservedComponents in generation 2 of 10\n",
      "Model Number: 188 with model ZeroesNaive in generation 2 of 10\n",
      "Model Number: 189 with model ZeroesNaive in generation 2 of 10\n",
      "Model Number: 190 with model ZeroesNaive in generation 2 of 10\n",
      "Model Number: 191 with model WindowRegression in generation 2 of 10\n",
      "Template Eval Error: ValueError(\"WindowRegression regression_type='user' requires numpy >= 1.20\") in model 191: WindowRegression\n",
      "Model Number: 192 with model WindowRegression in generation 2 of 10\n",
      "Template Eval Error: ValueError(\"WindowRegression regression_type='user' requires numpy >= 1.20\") in model 192: WindowRegression\n",
      "Model Number: 193 with model WindowRegression in generation 2 of 10\n",
      "Template Eval Error: ValueError(\"WindowRegression regression_type='user' requires numpy >= 1.20\") in model 193: WindowRegression\n",
      "Model Number: 194 with model GLM in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:278: DomainWarning: The inverse_power link function does not respect the domain of the Gamma family.\n",
      "  DomainWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 195 with model GLM in generation 2 of 10\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 195: GLM\n",
      "Model Number: 196 with model GLM in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:428: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:134: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 197 with model GLM in generation 2 of 10\n",
      "Model Number: 198 with model DatepartRegression in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 199 with model DatepartRegression in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 200 with model DatepartRegression in generation 2 of 10\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 201 with model GLS in generation 2 of 10\n",
      "Model Number: 202 with model GLS in generation 2 of 10\n",
      "Model Number: 203 with model GLS in generation 2 of 10\n",
      "Model Number: 204 with model GluonTS in generation 2 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 204: GluonTS\n",
      "Model Number: 205 with model GluonTS in generation 2 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 205: GluonTS\n",
      "Model Number: 206 with model GluonTS in generation 2 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 206: GluonTS\n",
      "Model Number: 207 with model GluonTS in generation 2 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 207: GluonTS\n",
      "Model Number: 208 with model VAR in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 208: VAR\n",
      "Model Number: 209 with model VAR in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 209: VAR\n",
      "Model Number: 210 with model VAR in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 210: VAR\n",
      "Model Number: 211 with model VAR in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 211: VAR\n",
      "Model Number: 212 with model VECM in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 212: VECM\n",
      "Model Number: 213 with model VECM in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 213: VECM\n",
      "Model Number: 214 with model VECM in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 214: VECM\n",
      "Model Number: 215 with model VECM in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 215: VECM\n",
      "Model Number: 216 with model FBProphet in generation 2 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 216: FBProphet\n",
      "Model Number: 217 with model FBProphet in generation 2 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 217: FBProphet\n",
      "Model Number: 218 with model FBProphet in generation 2 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 218: FBProphet\n",
      "Model Number: 219 with model FBProphet in generation 2 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 219: FBProphet\n",
      "Model Number: 220 with model UnivariateRegression in generation 2 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 220: UnivariateRegression\n",
      "Model Number: 221 with model UnivariateRegression in generation 2 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 221: UnivariateRegression\n",
      "Model Number: 222 with model UnivariateRegression in generation 2 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 222: UnivariateRegression\n",
      "Model Number: 223 with model UnivariateRegression in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2995: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 223: UnivariateRegression\n",
      "Model Number: 224 with model UnivariateMotif in generation 2 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 224: UnivariateMotif\n",
      "Model Number: 225 with model UnivariateMotif in generation 2 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 225: UnivariateMotif\n",
      "Model Number: 226 with model UnivariateMotif in generation 2 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 226: UnivariateMotif\n",
      "Model Number: 227 with model UnivariateMotif in generation 2 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 227: UnivariateMotif\n",
      "New Generation: 3 of 10\n",
      "Model Number: 228 with model RollingRegression in generation 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 229 with model RollingRegression in generation 3 of 10\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 229: RollingRegression\n",
      "Model Number: 230 with model RollingRegression in generation 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 231 with model RollingRegression in generation 3 of 10\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 231: RollingRegression\n",
      "Model Number: 232 with model LastValueNaive in generation 3 of 10\n",
      "Model Number: 233 with model LastValueNaive in generation 3 of 10\n",
      "Model Number: 234 with model LastValueNaive in generation 3 of 10\n",
      "Model Number: 235 with model ETS in generation 3 of 10\n",
      "Model Number: 236 with model ETS in generation 3 of 10\n",
      "Model Number: 237 with model ETS in generation 3 of 10\n",
      "Model Number: 238 with model ETS in generation 3 of 10\n",
      "Model Number: 239 with model SeasonalNaive in generation 3 of 10\n",
      "Model Number: 240 with model SeasonalNaive in generation 3 of 10\n",
      "Model Number: 241 with model SeasonalNaive in generation 3 of 10\n",
      "Model Number: 242 with model SeasonalNaive in generation 3 of 10\n",
      "Model Number: 243 with model AverageValueNaive in generation 3 of 10\n",
      "Model Number: 244 with model AverageValueNaive in generation 3 of 10\n",
      "Model Number: 245 with model AverageValueNaive in generation 3 of 10\n",
      "Model Number: 246 with model ZeroesNaive in generation 3 of 10\n",
      "Model Number: 247 with model ZeroesNaive in generation 3 of 10\n",
      "Model Number: 248 with model ZeroesNaive in generation 3 of 10\n",
      "Model Number: 249 with model UnobservedComponents in generation 3 of 10\n",
      "Model Number: 250 with model UnobservedComponents in generation 3 of 10\n",
      "Model Number: 251 with model UnobservedComponents in generation 3 of 10\n",
      "Model Number: 252 with model GLS in generation 3 of 10\n",
      "Model Number: 253 with model GLS in generation 3 of 10\n",
      "Model Number: 254 with model GLS in generation 3 of 10\n",
      "Model Number: 255 with model GLM in generation 3 of 10\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 255: GLM\n",
      "Model Number: 256 with model GLM in generation 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1443: RuntimeWarning: invalid value encountered in log\n",
      "  endog * np.log(endog / mu) + (mu - endog))\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1443: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  endog * np.log(endog / mu) + (mu - endog))\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:774: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.sum(resid / self.family.variance(mu)) / self.df_resid\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:134: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: KeyError(Timestamp('2021-06-25 00:00:00', freq='D')) in model 256: GLM\n",
      "Model Number: 257 with model GLM in generation 3 of 10\n",
      "Model Number: 258 with model GLM in generation 3 of 10\n",
      "Model Number: 259 with model WindowRegression in generation 3 of 10\n",
      "Template Eval Error: ValueError('Length mismatch: Expected axis has 191 elements, new values have 1 elements') in model 259: WindowRegression\n",
      "Model Number: 260 with model WindowRegression in generation 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:978: RuntimeWarning: All-NaN slice encountered\n",
      "  max_abs = np.nanmax(np.abs(X), axis=0)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:978: RuntimeWarning: All-NaN slice encountered\n",
      "  max_abs = np.nanmax(np.abs(X), axis=0)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:373: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:374: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Length mismatch: Expected axis has 191 elements, new values have 1 elements') in model 260: WindowRegression\n",
      "Model Number: 261 with model WindowRegression in generation 3 of 10\n",
      "Template Eval Error: ValueError('Length mismatch: Expected axis has 191 elements, new values have 1 elements') in model 261: WindowRegression\n",
      "Model Number: 262 with model DatepartRegression in generation 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:366: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series') in model 262: DatepartRegression\n",
      "Model Number: 263 with model DatepartRegression in generation 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:1522: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model = self.model.fit(X, y)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:366: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 264 with model DatepartRegression in generation 3 of 10\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series') in model 264: DatepartRegression\n",
      "Model Number: 265 with model GluonTS in generation 3 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 265: GluonTS\n",
      "Model Number: 266 with model GluonTS in generation 3 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 266: GluonTS\n",
      "Model Number: 267 with model GluonTS in generation 3 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 267: GluonTS\n",
      "Model Number: 268 with model GluonTS in generation 3 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 268: GluonTS\n",
      "Model Number: 269 with model VAR in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 269: VAR\n",
      "Model Number: 270 with model VAR in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 270: VAR\n",
      "Model Number: 271 with model VAR in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 271: VAR\n",
      "Model Number: 272 with model VAR in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 272: VAR\n",
      "Model Number: 273 with model VECM in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 273: VECM\n",
      "Model Number: 274 with model VECM in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 274: VECM\n",
      "Model Number: 275 with model VECM in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 275: VECM\n",
      "Model Number: 276 with model VECM in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 276: VECM\n",
      "Model Number: 277 with model FBProphet in generation 3 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 277: FBProphet\n",
      "Model Number: 278 with model FBProphet in generation 3 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 278: FBProphet\n",
      "Model Number: 279 with model FBProphet in generation 3 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 279: FBProphet\n",
      "Model Number: 280 with model FBProphet in generation 3 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 280: FBProphet\n",
      "Model Number: 281 with model UnivariateRegression in generation 3 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 281: UnivariateRegression\n",
      "Model Number: 282 with model UnivariateRegression in generation 3 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 282: UnivariateRegression\n",
      "Model Number: 283 with model UnivariateRegression in generation 3 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 283: UnivariateRegression\n",
      "Model Number: 284 with model UnivariateRegression in generation 3 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 284: UnivariateRegression\n",
      "Model Number: 285 with model UnivariateMotif in generation 3 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 285: UnivariateMotif\n",
      "Model Number: 286 with model UnivariateMotif in generation 3 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 286: UnivariateMotif\n",
      "Model Number: 287 with model UnivariateMotif in generation 3 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 287: UnivariateMotif\n",
      "Model Number: 288 with model UnivariateMotif in generation 3 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 288: UnivariateMotif\n",
      "New Generation: 4 of 10\n",
      "Model Number: 289 with model RollingRegression in generation 4 of 10\n",
      "Model Number: 290 with model RollingRegression in generation 4 of 10\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 290: RollingRegression\n",
      "Model Number: 291 with model RollingRegression in generation 4 of 10\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 291: RollingRegression\n",
      "Model Number: 292 with model RollingRegression in generation 4 of 10\n",
      "Model Number: 293 with model LastValueNaive in generation 4 of 10\n",
      "Model Number: 294 with model LastValueNaive in generation 4 of 10\n",
      "Model Number: 295 with model ETS in generation 4 of 10\n",
      "Template Eval Error: ValueError('Cannot convert non-finite values (NA or inf) to integer') in model 295: ETS\n",
      "Model Number: 296 with model ETS in generation 4 of 10\n",
      "Model Number: 297 with model ETS in generation 4 of 10\n",
      "Model Number: 298 with model ETS in generation 4 of 10\n",
      "Model Number: 299 with model SeasonalNaive in generation 4 of 10\n",
      "Model Number: 300 with model SeasonalNaive in generation 4 of 10\n",
      "Model Number: 301 with model SeasonalNaive in generation 4 of 10\n",
      "Model Number: 302 with model SeasonalNaive in generation 4 of 10\n",
      "Model Number: 303 with model AverageValueNaive in generation 4 of 10\n",
      "Model Number: 304 with model AverageValueNaive in generation 4 of 10\n",
      "Model Number: 305 with model AverageValueNaive in generation 4 of 10\n",
      "Model Number: 306 with model ZeroesNaive in generation 4 of 10\n",
      "Model Number: 307 with model ZeroesNaive in generation 4 of 10\n",
      "Model Number: 308 with model ZeroesNaive in generation 4 of 10\n",
      "Model Number: 309 with model UnobservedComponents in generation 4 of 10\n",
      "Model Number: 310 with model UnobservedComponents in generation 4 of 10\n",
      "Model Number: 311 with model UnobservedComponents in generation 4 of 10\n",
      "Model Number: 312 with model GLS in generation 4 of 10\n",
      "Model Number: 313 with model GLS in generation 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2995: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Length mismatch: Expected axis has 191 elements, new values have 1 elements') in model 313: GLS\n",
      "Model Number: 314 with model GLS in generation 4 of 10\n",
      "Model Number: 315 with model GLM in generation 4 of 10\n",
      "Model Number: 316 with model GLM in generation 4 of 10\n",
      "Model Number: 317 with model GLM in generation 4 of 10\n",
      "Model Number: 318 with model GLM in generation 4 of 10\n",
      "Model Number: 319 with model WindowRegression in generation 4 of 10\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 320 with model WindowRegression in generation 4 of 10\n",
      "Template Eval Error: ValueError(\"WindowRegression regression_type='user' requires numpy >= 1.20\") in model 320: WindowRegression\n",
      "Model Number: 321 with model WindowRegression in generation 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 322 with model DatepartRegression in generation 4 of 10\n",
      "Model Number: 323 with model DatepartRegression in generation 4 of 10\n",
      "Model Number: 324 with model DatepartRegression in generation 4 of 10\n",
      "Model Number: 325 with model GluonTS in generation 4 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 325: GluonTS\n",
      "Model Number: 326 with model GluonTS in generation 4 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 326: GluonTS\n",
      "Model Number: 327 with model GluonTS in generation 4 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 327: GluonTS\n",
      "Model Number: 328 with model GluonTS in generation 4 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 328: GluonTS\n",
      "Model Number: 329 with model VAR in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 329: VAR\n",
      "Model Number: 330 with model VAR in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 330: VAR\n",
      "Model Number: 331 with model VAR in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 331: VAR\n",
      "Model Number: 332 with model VAR in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 332: VAR\n",
      "Model Number: 333 with model VECM in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 333: VECM\n",
      "Model Number: 334 with model VECM in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 334: VECM\n",
      "Model Number: 335 with model VECM in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 335: VECM\n",
      "Model Number: 336 with model VECM in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 336: VECM\n",
      "Model Number: 337 with model FBProphet in generation 4 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 337: FBProphet\n",
      "Model Number: 338 with model FBProphet in generation 4 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 338: FBProphet\n",
      "Model Number: 339 with model FBProphet in generation 4 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 339: FBProphet\n",
      "Model Number: 340 with model FBProphet in generation 4 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 340: FBProphet\n",
      "Model Number: 341 with model UnivariateRegression in generation 4 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 341: UnivariateRegression\n",
      "Model Number: 342 with model UnivariateRegression in generation 4 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 342: UnivariateRegression\n",
      "Model Number: 343 with model UnivariateRegression in generation 4 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 343: UnivariateRegression\n",
      "Model Number: 344 with model UnivariateRegression in generation 4 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 344: UnivariateRegression\n",
      "Model Number: 345 with model UnivariateMotif in generation 4 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 345: UnivariateMotif\n",
      "Model Number: 346 with model UnivariateMotif in generation 4 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 346: UnivariateMotif\n",
      "Model Number: 347 with model UnivariateMotif in generation 4 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 347: UnivariateMotif\n",
      "Model Number: 348 with model UnivariateMotif in generation 4 of 10\n",
      "Template Eval Error: ValueError('zero-size array to reduction operation maximum which has no identity') in model 348: UnivariateMotif\n",
      "New Generation: 5 of 10\n",
      "Model Number: 349 with model RollingRegression in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 350 with model RollingRegression in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 351 with model RollingRegression in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 352 with model RollingRegression in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 353 with model LastValueNaive in generation 5 of 10\n",
      "Model Number: 354 with model LastValueNaive in generation 5 of 10\n",
      "Model Number: 355 with model LastValueNaive in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Length mismatch: Expected axis has 191 elements, new values have 1 elements') in model 355: LastValueNaive\n",
      "Model Number: 356 with model WindowRegression in generation 5 of 10\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 357 with model WindowRegression in generation 5 of 10\n",
      "Template Eval Error: ValueError(\"WindowRegression regression_type='user' requires numpy >= 1.20\") in model 357: WindowRegression\n",
      "Model Number: 358 with model WindowRegression in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:1065: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 359 with model ETS in generation 5 of 10\n",
      "Model Number: 360 with model ETS in generation 5 of 10\n",
      "Model Number: 361 with model ETS in generation 5 of 10\n",
      "Model Number: 362 with model SeasonalNaive in generation 5 of 10\n",
      "Model Number: 363 with model SeasonalNaive in generation 5 of 10\n",
      "Model Number: 364 with model SeasonalNaive in generation 5 of 10\n",
      "Model Number: 365 with model SeasonalNaive in generation 5 of 10\n",
      "Model Number: 366 with model AverageValueNaive in generation 5 of 10\n",
      "Model Number: 367 with model AverageValueNaive in generation 5 of 10\n",
      "Model Number: 368 with model AverageValueNaive in generation 5 of 10\n",
      "Model Number: 369 with model GLS in generation 5 of 10\n",
      "Model Number: 370 with model GLS in generation 5 of 10\n",
      "Model Number: 371 with model GLS in generation 5 of 10\n",
      "Model Number: 372 with model ZeroesNaive in generation 5 of 10\n",
      "Model Number: 373 with model ZeroesNaive in generation 5 of 10\n",
      "Model Number: 374 with model ZeroesNaive in generation 5 of 10\n",
      "Model Number: 375 with model UnobservedComponents in generation 5 of 10\n",
      "Model Number: 376 with model UnobservedComponents in generation 5 of 10\n",
      "Model Number: 377 with model UnobservedComponents in generation 5 of 10\n",
      "Model Number: 378 with model GLM in generation 5 of 10\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 378: GLM\n",
      "Model Number: 379 with model GLM in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:428: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:134: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 380 with model GLM in generation 5 of 10\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 380: GLM\n",
      "Model Number: 381 with model GLM in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1443: RuntimeWarning: invalid value encountered in log\n",
      "  endog * np.log(endog / mu) + (mu - endog))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 382 with model DatepartRegression in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1370: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input, interpolation=interpolation\n",
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:1522: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model = self.model.fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Length mismatch: Expected axis has 191 elements, new values have 1 elements') in model 382: DatepartRegression\n",
      "Model Number: 383 with model DatepartRegression in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 384 with model DatepartRegression in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 385 with model GluonTS in generation 5 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 385: GluonTS\n",
      "Model Number: 386 with model GluonTS in generation 5 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 386: GluonTS\n",
      "Model Number: 387 with model GluonTS in generation 5 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 387: GluonTS\n",
      "Model Number: 388 with model GluonTS in generation 5 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 388: GluonTS\n",
      "Model Number: 389 with model VAR in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 389: VAR\n",
      "Model Number: 390 with model VAR in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 390: VAR\n",
      "Model Number: 391 with model VAR in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 391: VAR\n",
      "Model Number: 392 with model VAR in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 392: VAR\n",
      "Model Number: 393 with model VECM in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 393: VECM\n",
      "Model Number: 394 with model VECM in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 394: VECM\n",
      "Model Number: 395 with model VECM in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 395: VECM\n",
      "Model Number: 396 with model VECM in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 396: VECM\n",
      "Model Number: 397 with model FBProphet in generation 5 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 397: FBProphet\n",
      "Model Number: 398 with model FBProphet in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1390: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input, interpolation)\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1390: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input, interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ImportError('Package fbprophet is required') in model 398: FBProphet\n",
      "Model Number: 399 with model FBProphet in generation 5 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 399: FBProphet\n",
      "Model Number: 400 with model FBProphet in generation 5 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 400: FBProphet\n",
      "Model Number: 401 with model UnivariateRegression in generation 5 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 401: UnivariateRegression\n",
      "Model Number: 402 with model UnivariateRegression in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:2551: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 402: UnivariateRegression\n",
      "Model Number: 403 with model UnivariateRegression in generation 5 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 403: UnivariateRegression\n",
      "Model Number: 404 with model UnivariateRegression in generation 5 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 404: UnivariateRegression\n",
      "Model Number: 405 with model UnivariateMotif in generation 5 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 405: UnivariateMotif\n",
      "Model Number: 406 with model UnivariateMotif in generation 5 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 406: UnivariateMotif\n",
      "Model Number: 407 with model UnivariateMotif in generation 5 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 407: UnivariateMotif\n",
      "Model Number: 408 with model UnivariateMotif in generation 5 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 408: UnivariateMotif\n",
      "New Generation: 6 of 10\n",
      "Model Number: 409 with model RollingRegression in generation 6 of 10\n",
      "Model Number: 410 with model RollingRegression in generation 6 of 10\n",
      "Model Number: 411 with model RollingRegression in generation 6 of 10\n",
      "Model Number: 412 with model RollingRegression in generation 6 of 10\n",
      "Model Number: 413 with model LastValueNaive in generation 6 of 10\n",
      "Model Number: 414 with model LastValueNaive in generation 6 of 10\n",
      "Model Number: 415 with model LastValueNaive in generation 6 of 10\n",
      "Model Number: 416 with model WindowRegression in generation 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:1065: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 417 with model WindowRegression in generation 6 of 10\n",
      "Model Number: 418 with model WindowRegression in generation 6 of 10\n",
      "Template Eval Error: ValueError(\"WindowRegression regression_type='user' requires numpy >= 1.20\") in model 418: WindowRegression\n",
      "Model Number: 419 with model ETS in generation 6 of 10\n",
      "Model Number: 420 with model ETS in generation 6 of 10\n",
      "Model Number: 421 with model ETS in generation 6 of 10\n",
      "Model Number: 422 with model ETS in generation 6 of 10\n",
      "Model Number: 423 with model SeasonalNaive in generation 6 of 10\n",
      "Model Number: 424 with model SeasonalNaive in generation 6 of 10\n",
      "Model Number: 425 with model SeasonalNaive in generation 6 of 10\n",
      "Model Number: 426 with model SeasonalNaive in generation 6 of 10\n",
      "Model Number: 427 with model GLS in generation 6 of 10\n",
      "Model Number: 428 with model GLS in generation 6 of 10\n",
      "Model Number: 429 with model GLS in generation 6 of 10\n",
      "Model Number: 430 with model GLM in generation 6 of 10\n",
      "Model Number: 431 with model GLM in generation 6 of 10\n",
      "Model Number: 432 with model GLM in generation 6 of 10\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 432: GLM\n",
      "Model Number: 433 with model GLM in generation 6 of 10\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 433: GLM\n",
      "Model Number: 434 with model AverageValueNaive in generation 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1443: RuntimeWarning: invalid value encountered in log\n",
      "  endog * np.log(endog / mu) + (mu - endog))\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1230: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 435 with model AverageValueNaive in generation 6 of 10\n",
      "Model Number: 436 with model AverageValueNaive in generation 6 of 10\n",
      "Model Number: 437 with model ZeroesNaive in generation 6 of 10\n",
      "Model Number: 438 with model ZeroesNaive in generation 6 of 10\n",
      "Model Number: 439 with model ZeroesNaive in generation 6 of 10\n",
      "Model Number: 440 with model DatepartRegression in generation 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 441 with model DatepartRegression in generation 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 442 with model DatepartRegression in generation 6 of 10\n",
      "Model Number: 443 with model UnobservedComponents in generation 6 of 10\n",
      "Model Number: 444 with model UnobservedComponents in generation 6 of 10\n",
      "Model Number: 445 with model UnobservedComponents in generation 6 of 10\n",
      "Model Number: 446 with model GluonTS in generation 6 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 446: GluonTS\n",
      "Model Number: 447 with model GluonTS in generation 6 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 447: GluonTS\n",
      "Model Number: 448 with model GluonTS in generation 6 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 448: GluonTS\n",
      "Model Number: 449 with model GluonTS in generation 6 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 449: GluonTS\n",
      "Model Number: 450 with model VAR in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 450: VAR\n",
      "Model Number: 451 with model VAR in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 451: VAR\n",
      "Model Number: 452 with model VAR in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 452: VAR\n",
      "Model Number: 453 with model VAR in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 453: VAR\n",
      "Model Number: 454 with model VECM in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 454: VECM\n",
      "Model Number: 455 with model VECM in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 455: VECM\n",
      "Model Number: 456 with model VECM in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 456: VECM\n",
      "Model Number: 457 with model VECM in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 457: VECM\n",
      "Model Number: 458 with model FBProphet in generation 6 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 458: FBProphet\n",
      "Model Number: 459 with model FBProphet in generation 6 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 459: FBProphet\n",
      "Model Number: 460 with model FBProphet in generation 6 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 460: FBProphet\n",
      "Model Number: 461 with model FBProphet in generation 6 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 461: FBProphet\n",
      "Model Number: 462 with model UnivariateRegression in generation 6 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 462: UnivariateRegression\n",
      "Model Number: 463 with model UnivariateRegression in generation 6 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 463: UnivariateRegression\n",
      "Model Number: 464 with model UnivariateRegression in generation 6 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 464: UnivariateRegression\n",
      "Model Number: 465 with model UnivariateRegression in generation 6 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 465: UnivariateRegression\n",
      "Model Number: 466 with model UnivariateMotif in generation 6 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 466: UnivariateMotif\n",
      "Model Number: 467 with model UnivariateMotif in generation 6 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 467: UnivariateMotif\n",
      "Model Number: 468 with model UnivariateMotif in generation 6 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 468: UnivariateMotif\n",
      "Model Number: 469 with model UnivariateMotif in generation 6 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 469: UnivariateMotif\n",
      "New Generation: 7 of 10\n",
      "Model Number: 470 with model RollingRegression in generation 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 471 with model RollingRegression in generation 7 of 10\n",
      "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 955)) while a minimum of 1 is required.') in model 471: RollingRegression\n",
      "Model Number: 472 with model RollingRegression in generation 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 473 with model RollingRegression in generation 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 474 with model LastValueNaive in generation 7 of 10\n",
      "Model Number: 475 with model LastValueNaive in generation 7 of 10\n",
      "Model Number: 476 with model LastValueNaive in generation 7 of 10\n",
      "Model Number: 477 with model WindowRegression in generation 7 of 10\n",
      "Model Number: 478 with model WindowRegression in generation 7 of 10\n",
      "Model Number: 479 with model WindowRegression in generation 7 of 10\n",
      "Template Eval Error: ValueError(\"WindowRegression regression_type='user' requires numpy >= 1.20\") in model 479: WindowRegression\n",
      "Model Number: 480 with model ETS in generation 7 of 10\n",
      "Model Number: 481 with model ETS in generation 7 of 10\n",
      "Model Number: 482 with model ETS in generation 7 of 10\n",
      "Model Number: 483 with model ETS in generation 7 of 10\n",
      "Model Number: 484 with model SeasonalNaive in generation 7 of 10\n",
      "Model Number: 485 with model SeasonalNaive in generation 7 of 10\n",
      "Model Number: 486 with model SeasonalNaive in generation 7 of 10\n",
      "Model Number: 487 with model SeasonalNaive in generation 7 of 10\n",
      "Model Number: 488 with model GLS in generation 7 of 10\n",
      "Model Number: 489 with model GLS in generation 7 of 10\n",
      "Model Number: 490 with model GLM in generation 7 of 10\n",
      "Model Number: 491 with model GLM in generation 7 of 10\n",
      "Model Number: 492 with model GLM in generation 7 of 10\n",
      "Model Number: 493 with model GLM in generation 7 of 10\n",
      "Model Number: 494 with model AverageValueNaive in generation 7 of 10\n",
      "Template Eval Error: ValueError('Length mismatch: Expected axis has 191 elements, new values have 1 elements') in model 494: AverageValueNaive\n",
      "Model Number: 495 with model AverageValueNaive in generation 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 496 with model AverageValueNaive in generation 7 of 10\n",
      "Model Number: 497 with model ZeroesNaive in generation 7 of 10\n",
      "Model Number: 498 with model ZeroesNaive in generation 7 of 10\n",
      "Model Number: 499 with model ZeroesNaive in generation 7 of 10\n",
      "Model Number: 500 with model DatepartRegression in generation 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 501 with model DatepartRegression in generation 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 502 with model DatepartRegression in generation 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 503 with model UnobservedComponents in generation 7 of 10\n",
      "Model Number: 504 with model UnobservedComponents in generation 7 of 10\n",
      "Model Number: 505 with model UnobservedComponents in generation 7 of 10\n",
      "Model Number: 506 with model GluonTS in generation 7 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 506: GluonTS\n",
      "Model Number: 507 with model GluonTS in generation 7 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 507: GluonTS\n",
      "Model Number: 508 with model GluonTS in generation 7 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 508: GluonTS\n",
      "Model Number: 509 with model GluonTS in generation 7 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 509: GluonTS\n",
      "Model Number: 510 with model VAR in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 510: VAR\n",
      "Model Number: 511 with model VAR in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 511: VAR\n",
      "Model Number: 512 with model VAR in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 512: VAR\n",
      "Model Number: 513 with model VAR in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 513: VAR\n",
      "Model Number: 514 with model VECM in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 514: VECM\n",
      "Model Number: 515 with model VECM in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 515: VECM\n",
      "Model Number: 516 with model VECM in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 516: VECM\n",
      "Model Number: 517 with model VECM in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 517: VECM\n",
      "Model Number: 518 with model FBProphet in generation 7 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 518: FBProphet\n",
      "Model Number: 519 with model FBProphet in generation 7 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 519: FBProphet\n",
      "Model Number: 520 with model FBProphet in generation 7 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 520: FBProphet\n",
      "Model Number: 521 with model FBProphet in generation 7 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 521: FBProphet\n",
      "Model Number: 522 with model UnivariateRegression in generation 7 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 522: UnivariateRegression\n",
      "Model Number: 523 with model UnivariateRegression in generation 7 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 523: UnivariateRegression\n",
      "Model Number: 524 with model UnivariateRegression in generation 7 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 524: UnivariateRegression\n",
      "Model Number: 525 with model UnivariateRegression in generation 7 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 525: UnivariateRegression\n",
      "Model Number: 526 with model UnivariateMotif in generation 7 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 526: UnivariateMotif\n",
      "Model Number: 527 with model UnivariateMotif in generation 7 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 527: UnivariateMotif\n",
      "Model Number: 528 with model UnivariateMotif in generation 7 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 528: UnivariateMotif\n",
      "Model Number: 529 with model UnivariateMotif in generation 7 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 529: UnivariateMotif\n",
      "New Generation: 8 of 10\n",
      "Model Number: 530 with model WindowRegression in generation 8 of 10\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 531 with model WindowRegression in generation 8 of 10\n",
      "Template Eval Error: TypeError(\"Cannot clone object ''DecisionTree'' (type <class 'str'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\") in model 531: WindowRegression\n",
      "Model Number: 532 with model WindowRegression in generation 8 of 10\n",
      "Template Eval Error: ValueError('at least one array or dtype is required') in model 532: WindowRegression\n",
      "Model Number: 533 with model RollingRegression in generation 8 of 10\n",
      "Template Eval Error: TypeError(\"Cannot clone object ''DecisionTree'' (type <class 'str'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\") in model 533: RollingRegression\n",
      "Model Number: 534 with model RollingRegression in generation 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 535 with model RollingRegression in generation 8 of 10\n",
      "Template Eval Error: TypeError(\"Cannot clone object ''DecisionTree'' (type <class 'str'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\") in model 535: RollingRegression\n",
      "Model Number: 536 with model RollingRegression in generation 8 of 10\n",
      "Template Eval Error: TypeError(\"Cannot clone object ''DecisionTree'' (type <class 'str'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\") in model 536: RollingRegression\n",
      "Model Number: 537 with model LastValueNaive in generation 8 of 10\n",
      "Model Number: 538 with model LastValueNaive in generation 8 of 10\n",
      "Model Number: 539 with model LastValueNaive in generation 8 of 10\n",
      "Model Number: 540 with model ETS in generation 8 of 10\n",
      "Model Number: 541 with model ETS in generation 8 of 10\n",
      "Model Number: 542 with model ETS in generation 8 of 10\n",
      "Model Number: 543 with model ETS in generation 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2995: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Length mismatch: Expected axis has 191 elements, new values have 1 elements') in model 543: ETS\n",
      "Model Number: 544 with model SeasonalNaive in generation 8 of 10\n",
      "Model Number: 545 with model SeasonalNaive in generation 8 of 10\n",
      "Model Number: 546 with model SeasonalNaive in generation 8 of 10\n",
      "Model Number: 547 with model SeasonalNaive in generation 8 of 10\n",
      "Model Number: 548 with model GLS in generation 8 of 10\n",
      "Model Number: 549 with model GLS in generation 8 of 10\n",
      "Model Number: 550 with model GLS in generation 8 of 10\n",
      "Model Number: 551 with model GLM in generation 8 of 10\n",
      "Model Number: 552 with model GLM in generation 8 of 10\n",
      "Model Number: 553 with model GLM in generation 8 of 10\n",
      "Model Number: 554 with model GLM in generation 8 of 10\n",
      "Model Number: 555 with model AverageValueNaive in generation 8 of 10\n",
      "Model Number: 556 with model AverageValueNaive in generation 8 of 10\n",
      "Model Number: 557 with model AverageValueNaive in generation 8 of 10\n",
      "Model Number: 558 with model DatepartRegression in generation 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:1522: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model = self.model.fit(X, y)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 559 with model DatepartRegression in generation 8 of 10\n",
      "Model Number: 560 with model DatepartRegression in generation 8 of 10\n",
      "Model Number: 561 with model ZeroesNaive in generation 8 of 10\n",
      "Model Number: 562 with model ZeroesNaive in generation 8 of 10\n",
      "Model Number: 563 with model ZeroesNaive in generation 8 of 10\n",
      "Model Number: 564 with model UnobservedComponents in generation 8 of 10\n",
      "Model Number: 565 with model UnobservedComponents in generation 8 of 10\n",
      "Model Number: 566 with model UnobservedComponents in generation 8 of 10\n",
      "Model Number: 567 with model GluonTS in generation 8 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 567: GluonTS\n",
      "Model Number: 568 with model GluonTS in generation 8 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 568: GluonTS\n",
      "Model Number: 569 with model GluonTS in generation 8 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 569: GluonTS\n",
      "Model Number: 570 with model GluonTS in generation 8 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 570: GluonTS\n",
      "Model Number: 571 with model VAR in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 571: VAR\n",
      "Model Number: 572 with model VAR in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 572: VAR\n",
      "Model Number: 573 with model VAR in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 573: VAR\n",
      "Model Number: 574 with model VAR in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 574: VAR\n",
      "Model Number: 575 with model VECM in generation 8 of 10\n",
      "Template Eval Error: LinAlgError('SVD did not converge') in model 575: VECM\n",
      "Model Number: 576 with model VECM in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 576: VECM\n",
      "Model Number: 577 with model VECM in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 577: VECM\n",
      "Model Number: 578 with model VECM in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 578: VECM\n",
      "Model Number: 579 with model FBProphet in generation 8 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 579: FBProphet\n",
      "Model Number: 580 with model FBProphet in generation 8 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 580: FBProphet\n",
      "Model Number: 581 with model FBProphet in generation 8 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 581: FBProphet\n",
      "Model Number: 582 with model FBProphet in generation 8 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 582: FBProphet\n",
      "Model Number: 583 with model UnivariateRegression in generation 8 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 583: UnivariateRegression\n",
      "Model Number: 584 with model UnivariateRegression in generation 8 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 584: UnivariateRegression\n",
      "Model Number: 585 with model UnivariateRegression in generation 8 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 585: UnivariateRegression\n",
      "Model Number: 586 with model UnivariateRegression in generation 8 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 586: UnivariateRegression\n",
      "Model Number: 587 with model UnivariateMotif in generation 8 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 587: UnivariateMotif\n",
      "Model Number: 588 with model UnivariateMotif in generation 8 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 588: UnivariateMotif\n",
      "Model Number: 589 with model UnivariateMotif in generation 8 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 589: UnivariateMotif\n",
      "Model Number: 590 with model UnivariateMotif in generation 8 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 590: UnivariateMotif\n",
      "New Generation: 9 of 10\n",
      "Model Number: 591 with model WindowRegression in generation 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 592 with model WindowRegression in generation 9 of 10\n",
      "Model Number: 593 with model WindowRegression in generation 9 of 10\n",
      "Model Number: 594 with model RollingRegression in generation 9 of 10\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 594: RollingRegression\n",
      "Model Number: 595 with model RollingRegression in generation 9 of 10\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 9s 8ms/step - loss: 0.9700\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9680\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9668\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9642\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9597\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9535\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9445\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9319\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9174\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8972\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8757\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8607\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8375\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8210\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8016\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7858\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7676\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7607\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7498\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7312\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7270\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7077\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6985\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6681\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6569\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6401\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6272\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6076\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5834\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5730\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5451\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5409\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4867\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4916\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4597\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4394\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4328\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4114\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4057\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3759\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3716\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3709\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3612\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3579\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3456\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3316\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3317\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3273\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3271\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3237\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3186\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3173\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3240\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3284\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3106\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3227\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3120\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3053\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3042\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3086\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3223\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3002\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3054\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2978\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2998\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2860\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2925\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2912\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2940\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3027\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2894\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2954\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3130\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3010\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2958\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2834\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2858\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2889\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3057\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2948\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2934\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2989\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2958\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2876\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2825\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3055\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2802\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2818\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2836\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2997\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2856\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2873\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2859\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2901\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2868\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2958\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2775\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2847\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2813\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2843\n",
      "Model Number: 596 with model RollingRegression in generation 9 of 10\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 596: RollingRegression\n",
      "Model Number: 597 with model RollingRegression in generation 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 598 with model DatepartRegression in generation 9 of 10\n",
      "Model Number: 599 with model DatepartRegression in generation 9 of 10\n",
      "Model Number: 600 with model DatepartRegression in generation 9 of 10\n",
      "Model Number: 601 with model LastValueNaive in generation 9 of 10\n",
      "Model Number: 602 with model LastValueNaive in generation 9 of 10\n",
      "Model Number: 603 with model LastValueNaive in generation 9 of 10\n",
      "Model Number: 604 with model ETS in generation 9 of 10\n",
      "Model Number: 605 with model ETS in generation 9 of 10\n",
      "Model Number: 606 with model ETS in generation 9 of 10\n",
      "Model Number: 607 with model ETS in generation 9 of 10\n",
      "Model Number: 608 with model SeasonalNaive in generation 9 of 10\n",
      "Model Number: 609 with model SeasonalNaive in generation 9 of 10\n",
      "Model Number: 610 with model SeasonalNaive in generation 9 of 10\n",
      "Model Number: 611 with model SeasonalNaive in generation 9 of 10\n",
      "Model Number: 612 with model AverageValueNaive in generation 9 of 10\n",
      "Model Number: 613 with model AverageValueNaive in generation 9 of 10\n",
      "Model Number: 614 with model AverageValueNaive in generation 9 of 10\n",
      "Model Number: 615 with model GLS in generation 9 of 10\n",
      "Model Number: 616 with model GLS in generation 9 of 10\n",
      "Model Number: 617 with model GLM in generation 9 of 10\n",
      "Model Number: 618 with model GLM in generation 9 of 10\n",
      "Model Number: 619 with model GLM in generation 9 of 10\n",
      "Model Number: 620 with model GLM in generation 9 of 10\n",
      "Model Number: 621 with model ZeroesNaive in generation 9 of 10\n",
      "Model Number: 622 with model ZeroesNaive in generation 9 of 10\n",
      "Template Eval Error: KeyError(Timestamp('2021-03-22 00:00:00', freq='D')) in model 622: ZeroesNaive\n",
      "Model Number: 623 with model ZeroesNaive in generation 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1390: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input, interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Length mismatch: Expected axis has 191 elements, new values have 1 elements') in model 623: ZeroesNaive\n",
      "Model Number: 624 with model UnobservedComponents in generation 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:978: RuntimeWarning: All-NaN slice encountered\n",
      "  max_abs = np.nanmax(np.abs(X), axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 625 with model UnobservedComponents in generation 9 of 10\n",
      "Model Number: 626 with model UnobservedComponents in generation 9 of 10\n",
      "Model Number: 627 with model GluonTS in generation 9 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 627: GluonTS\n",
      "Model Number: 628 with model GluonTS in generation 9 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 628: GluonTS\n",
      "Model Number: 629 with model GluonTS in generation 9 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 629: GluonTS\n",
      "Model Number: 630 with model GluonTS in generation 9 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 630: GluonTS\n",
      "Model Number: 631 with model VAR in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 631: VAR\n",
      "Model Number: 632 with model VAR in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 632: VAR\n",
      "Model Number: 633 with model VAR in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 633: VAR\n",
      "Model Number: 634 with model VAR in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 634: VAR\n",
      "Model Number: 635 with model VECM in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 635: VECM\n",
      "Model Number: 636 with model VECM in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 636: VECM\n",
      "Model Number: 637 with model VECM in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 637: VECM\n",
      "Model Number: 638 with model FBProphet in generation 9 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 638: FBProphet\n",
      "Model Number: 639 with model FBProphet in generation 9 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 639: FBProphet\n",
      "Model Number: 640 with model FBProphet in generation 9 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 640: FBProphet\n",
      "Model Number: 641 with model FBProphet in generation 9 of 10\n",
      "Template Eval Error: ImportError('Package fbprophet is required') in model 641: FBProphet\n",
      "Model Number: 642 with model UnivariateRegression in generation 9 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 642: UnivariateRegression\n",
      "Model Number: 643 with model UnivariateRegression in generation 9 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 643: UnivariateRegression\n",
      "Model Number: 644 with model UnivariateRegression in generation 9 of 10\n",
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 644: UnivariateRegression\n",
      "Model Number: 645 with model UnivariateRegression in generation 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2995: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2995: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: TypeError(\"'>' not supported between instances of 'NoneType' and 'int'\") in model 645: UnivariateRegression\n",
      "Model Number: 646 with model UnivariateMotif in generation 9 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 646: UnivariateMotif\n",
      "Model Number: 647 with model UnivariateMotif in generation 9 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 647: UnivariateMotif\n",
      "Model Number: 648 with model UnivariateMotif in generation 9 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 648: UnivariateMotif\n",
      "Model Number: 649 with model UnivariateMotif in generation 9 of 10\n",
      "Template Eval Error: AttributeError(\"module 'numpy.lib.stride_tricks' has no attribute 'sliding_window_view'\") in model 649: UnivariateMotif\n",
      "New Generation: 10 of 10\n",
      "Model Number: 650 with model WindowRegression in generation 10 of 10\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 651 with model WindowRegression in generation 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError(\"loss='poisson' requires non-negative y and sum(y) > 0.\") in model 651: WindowRegression\n",
      "Model Number: 652 with model WindowRegression in generation 10 of 10\n",
      "Epoch 1/500\n",
      "6/6 [==============================] - 11s 11ms/step - loss: 0.0063\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0060\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0053\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0043\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0031\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0024\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0022\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0021\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0020\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0020\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0019\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0018\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0017\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0016\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0016\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0015\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0013\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0014\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0013\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0013\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0012\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0012\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0012\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0010\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0011\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0010\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.4644e-04\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0011\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.8704e-04\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0010\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.9811e-04\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0010\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.1009e-04\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0011\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.0474e-04\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.5161e-04\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.8295e-04\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.1270e-04\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.8685e-04\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.1868e-04\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.8178e-04\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.5872e-04\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.4001e-04\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4352e-04\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.3488e-04\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.3544e-04\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.7699e-04\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.5622e-04\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.9817e-04\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.3795e-04\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.4467e-04\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.2951e-04\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.1894e-04\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.1619e-04\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.0667e-04\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.7003e-04\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.3062e-04\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.9860e-04\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.3220e-04\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.4429e-04\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.3378e-04\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.0062e-04\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1252e-04\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.3637e-04\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.7140e-04\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.3338e-04\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.1608e-04\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.4223e-04\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.7813e-04\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.4410e-04\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.1224e-04\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 8.2976e-0 - 0s 14ms/step - loss: 7.9171e-04\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.3654e-04\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.3453e-04\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.8806e-04\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.0069e-04\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.7710e-04\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.2190e-04\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.3218e-04\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.4974e-04\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.4551e-04\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.2041e-04\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.8329e-04\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.9752e-04\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.8579e-04\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.3257e-04\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.7228e-04\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.6914e-04\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.9078e-04\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.5451e-04\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.4868e-04\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.8180e-04\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.1172e-04\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.1274e-04\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.5727e-04\n",
      "Epoch 97/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8054e-04\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9111e-04\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5871e-04\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.0091e-04\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.8693e-04\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3731e-04\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.7073e-04\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.2895e-04\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.6933e-04\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.8255e-04\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.9193e-04\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.7482e-04\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.7749e-04\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4842e-04\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9391e-04\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.3538e-04\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9244e-04\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.8783e-04\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.2593e-04\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.6593e-04\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4730e-04\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.2766e-04\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.3090e-04\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.6185e-04\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.5447e-04\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 8.4418e-0 - 0s 15ms/step - loss: 7.8641e-04\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1905e-04\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.7514e-04\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.7438e-04\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.2347e-04\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.6403e-04\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.9933e-04\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.5188e-04\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.7767e-04\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.2794e-04\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8899e-04\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.4342e-04\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.8247e-04\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.3750e-04\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.7595e-04\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.0483e-04\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.9360e-04\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.7553e-04\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.6115e-04\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.6056e-04\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.8284e-04\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.3904e-04\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.2781e-04\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.7414e-04\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.3664e-04\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.2519e-04\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9710e-04\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.6312e-04\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.0029e-04\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9341e-04\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.5207e-04\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9499e-04\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.3991e-04\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4416e-04\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.0748e-04\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.1097e-04\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.5321e-04\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.6138e-04\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.4328e-04\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.3986e-04\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.4202e-04\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.5468e-04\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2560e-04\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2868e-04\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2144e-04\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4937e-04\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6592e-04\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.9813e-04\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.9854e-04\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.7358e-04\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2523e-04\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.2524e-04\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.2323e-04\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.3333e-04\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.3236e-04\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.3530e-04\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.6802e-04\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.7282e-04\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.1509e-04\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8753e-04\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.6759e-04\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.1835e-04\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 7.5241e-0 - 0s 15ms/step - loss: 7.1976e-04\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9981e-04\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.3531e-04\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.7659e-04\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.3697e-04\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.0454e-04\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.9026e-04\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.5480e-04\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8895e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.6217e-04\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9601e-04\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6011e-04\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.6699e-04\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.4672e-04\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.5408e-04\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.2623e-04\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.7605e-04\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.5958e-04\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.4299e-04\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.5898e-04\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.3034e-04\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2877e-04\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.3216e-04\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.5012e-04\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.9107e-04\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.1240e-04\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3360e-04\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1533e-04\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9809e-04\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.3136e-04\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.8533e-04\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6313e-04\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9458e-04\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9787e-04\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.1943e-04\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.3980e-04\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.2404e-04\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.2153e-04\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6421e-04\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.5186e-04\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.9914e-04\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.8305e-04\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.7902e-04\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.8430e-04\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9996e-04\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.0017e-04\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.7186e-04\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.0244e-04\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2854e-04\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.8343e-04\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.1474e-04\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.7386e-04\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2672e-04\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.5509e-04\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.0140e-04\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 7.3635e-0 - 0s 14ms/step - loss: 6.9552e-04\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.1985e-04\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.6304e-04\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.6123e-04\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.2563e-04\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.7887e-04\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.5320e-04\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.3392e-04\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.7690e-04\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.8286e-04\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.3463e-04\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.4376e-04\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9063e-04\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.7068e-04\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.1329e-04\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.9774e-04\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.6946e-04\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.5727e-04\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.8772e-04\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5181e-04\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3529e-04\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.1337e-04\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.2659e-04\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.9925e-04\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.6630e-04\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8953e-04\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.4494e-04\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.8967e-04\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.5637e-04\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.6180e-04\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.8822e-04\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.1042e-04\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.4833e-04\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.6023e-04\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8312e-04\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.4497e-04\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.0376e-04\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.0683e-04\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.8166e-04\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.6719e-04\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.1067e-04\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.2772e-04\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.7047e-04\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.0246e-04\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9344e-04\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5263e-04\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.4112e-04\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.6898e-04\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1374e-04\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.8255e-04\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9188e-04\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.5815e-04\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.9454e-04\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.6001e-04\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.9301e-04\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.8328e-04\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.8073e-04\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.5977e-04\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.7510e-04\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.6202e-04\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.3710e-04\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.3068e-04\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.6974e-04\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.2642e-04\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.1802e-04\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.4358e-04\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.1350e-04\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.9312e-04\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.1778e-04\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7963e-04\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.2126e-04\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.4774e-04\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.0988e-04\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.3144e-04\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.5585e-04\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.6785e-04\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9468e-04\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.6981e-04\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.7825e-04\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.4485e-04\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6071e-04\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.0856e-04\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.1617e-04\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.6737e-04\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.3071e-04\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.4725e-04\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.8748e-04\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.0830e-04\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.3526e-04\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.5335e-04\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.9539e-04\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.1883e-04\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.8329e-04\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.0048e-04\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.6891e-04\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.0699e-04\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.2604e-04\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.3940e-04\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2350e-04\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1674e-04\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.6687e-04\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.2771e-04\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.7696e-04\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.2453e-04\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.5222e-04\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.3264e-04\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.4315e-04\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6617e-04\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 7.1484e-0 - ETA: 0s - loss: 7.1286e-0 - 0s 14ms/step - loss: 6.7576e-04\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.0633e-04\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2281e-04\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.5060e-04\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.5095e-04\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9098e-04\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.7779e-04\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.8500e-04\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.0018e-04\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.6042e-04\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9829e-04\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.4357e-04\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2308e-04\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.6886e-04\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.7333e-04\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.1494e-04\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.7606e-04\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.0934e-04\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.8858e-04\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.0385e-04\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.5689e-04\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.5497e-04\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.6541e-04\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4545e-04\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4948e-04\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8195e-04\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.3797e-04\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.0820e-04\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6604e-04\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.7575e-04\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.3280e-04\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.7990e-04\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.7282e-04\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.3490e-04\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.7162e-04\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9075e-04\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.0609e-04\n",
      "Epoch 384/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 17ms/step - loss: 7.3849e-04\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1775e-04\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.7458e-04\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.4129e-04\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.8855e-04\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.5098e-04\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1892e-04\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.9388e-04\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.0971e-04\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.9089e-04\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.3546e-04: 0s - loss: 6.6032e-0\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5396e-04\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.0608e-04\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.6798e-04\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.9049e-04\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7484e-04\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.9016e-04\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.1371e-04\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.5986e-04\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.7642e-04\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.7841e-04\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.8661e-04\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9417e-04\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 5.9826e-0 - 0s 16ms/step - loss: 6.1646e-04\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.0338e-04\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.0733e-04\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7288e-04\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.7732e-04\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.6564e-04\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4577e-04\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9270e-04\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.6753e-04\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.1534e-04\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.8585e-04\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.7804e-04\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.0348e-04\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.3052e-04\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9146e-04\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.0264e-04\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.7256e-04\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.5631e-04\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.2919e-04\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.3754e-04\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.4097e-04\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6467e-04\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.0449e-04\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9084e-04\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.1531e-04\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.4374e-04\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.7591e-04\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.3449e-04\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.6353e-04\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.3491e-04\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.9835e-04\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.6856e-04\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.4844e-04\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.2417e-04\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1408e-04\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.7882e-04\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.5231e-04\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.3933e-04\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.4254e-04\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.4341e-04\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.3542e-04\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.1833e-04\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2210e-04\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.5083e-04\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.9175e-04\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.7478e-04\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6488e-04\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.8074e-04\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.0540e-04\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.3613e-04\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.8234e-04\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.1189e-04\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9973e-04\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.0181e-04\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.5804e-04\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.7875e-04\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4284e-04\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.6136e-04\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.0464e-04\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.0548e-04\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.7043e-04\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.2841e-04\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7835e-04\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.2766e-04\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2162e-04\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8110e-04\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.6552e-04\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.8015e-04\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.4884e-04\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.0445e-04 - loss: 6.5904e-0\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.1929e-04\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8610e-04\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8975e-04\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9156e-04\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.7301e-04\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.8716e-04\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.5531e-04\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4781e-04\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3782e-04\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2295e-04\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.9190e-04\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4196e-04\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.2577e-04\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.9647e-04\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.9116e-04\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2983e-04\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.1856e-04\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.7024e-04\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 6.1629e-0 - 0s 16ms/step - loss: 6.3005e-04\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.3142e-04\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.6255e-04\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.9811e-04\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.5889e-04\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.8365e-04\n",
      "Model Number: 653 with model RollingRegression in generation 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 654 with model RollingRegression in generation 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 655 with model RollingRegression in generation 10 of 10\n",
      "Model Number: 656 with model RollingRegression in generation 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 657 with model DatepartRegression in generation 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 658 with model DatepartRegression in generation 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 659 with model DatepartRegression in generation 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:1522: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model = self.model.fit(X, y)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 660 with model LastValueNaive in generation 10 of 10\n",
      "Model Number: 661 with model LastValueNaive in generation 10 of 10\n",
      "Model Number: 662 with model LastValueNaive in generation 10 of 10\n",
      "Model Number: 663 with model ETS in generation 10 of 10\n",
      "Model Number: 664 with model ETS in generation 10 of 10\n",
      "Model Number: 665 with model ETS in generation 10 of 10\n",
      "Model Number: 666 with model SeasonalNaive in generation 10 of 10\n",
      "Model Number: 667 with model SeasonalNaive in generation 10 of 10\n",
      "Model Number: 668 with model SeasonalNaive in generation 10 of 10\n",
      "Model Number: 669 with model SeasonalNaive in generation 10 of 10\n",
      "Model Number: 670 with model AverageValueNaive in generation 10 of 10\n",
      "Model Number: 671 with model AverageValueNaive in generation 10 of 10\n",
      "Model Number: 672 with model AverageValueNaive in generation 10 of 10\n",
      "Model Number: 673 with model GLS in generation 10 of 10\n",
      "Model Number: 674 with model GLS in generation 10 of 10\n",
      "Model Number: 675 with model GLM in generation 10 of 10\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 675: GLM\n",
      "Model Number: 676 with model GLM in generation 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1443: RuntimeWarning: invalid value encountered in log\n",
      "  endog * np.log(endog / mu) + (mu - endog))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 677 with model GLM in generation 10 of 10\n",
      "Model Number: 678 with model GLM in generation 10 of 10\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 678: GLM\n",
      "Model Number: 679 with model ZeroesNaive in generation 10 of 10\n",
      "Model Number: 680 with model ZeroesNaive in generation 10 of 10\n",
      "Model Number: 681 with model ZeroesNaive in generation 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1230: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 682 with model UnobservedComponents in generation 10 of 10\n",
      "Model Number: 683 with model UnobservedComponents in generation 10 of 10\n",
      "Model Number: 684 with model UnobservedComponents in generation 10 of 10\n",
      "Model Number: 685 with model Ensemble in generation 11 of 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py:669: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.regr = self.regr.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 10s 13ms/step - loss: 0.0063\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0060\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0053\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0043\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0031\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0024\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0022\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0023\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0021\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0020\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0020\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0019\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0018\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0017\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0016\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0016\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0015\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0013\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0014\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0013\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0013\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0012\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0012\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0012 ETA: 0s - loss: 0.0012   \n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0010\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0011\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0010\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.4644e-04\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0011\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.8704e-04\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0010\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.9811e-04\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0010\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.1009e-04\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0011\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.0474e-04\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.5161e-04\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.8295e-04\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.1270e-04\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.8685e-04\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.1868e-04\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.8178e-04\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5872e-04\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.4001e-04\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4352e-04\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.3488e-04\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.3544e-04\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.7699e-04\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5622e-04\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.9817e-04\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3795e-04\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4467e-04\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2951e-04\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.1894e-04\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.1619e-04\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.0667e-04\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7003e-04\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3062e-04\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.9860e-04\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.3220e-04\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4429e-04\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3378e-04\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.0062e-04\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.1252e-04\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.3637e-04\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.7140e-04\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.3338e-04\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.1608e-04\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.4223e-04\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.7813e-04\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.4410e-04\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.1224e-04\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.9171e-04\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3654e-04\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.3453e-04\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.8806e-04\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.0069e-04\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.7710e-04\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.2190e-04\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.3218e-04\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.001 - 0s 8ms/step - loss: 9.4974e-04\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.4551e-04\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.2041e-04\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8329e-04\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.9752e-04\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.8579e-04\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.3257e-04\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.7228e-04\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.6914e-04\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.9078e-04\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5451e-04\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4868e-04\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.8180e-04\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.1172e-04\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1274e-04\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.5727e-04\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8054e-04\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9111e-04\n",
      "Epoch 99/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 10ms/step - loss: 7.5871e-04\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.0091e-04\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8693e-04\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.3731e-04\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.7073e-04\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.2895e-04\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.6933e-04\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8255e-04\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9193e-04\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.7482e-04\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.7749e-04\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.4842e-04\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.9391e-04\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.3538e-04\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.9244e-04\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.8783e-04\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2593e-04\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.6593e-04\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.4730e-04\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.2766e-04\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3090e-04\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.6185e-04\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.5447e-04\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.8641e-04\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1905e-04\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.7514e-04\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.7438e-04\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.2347e-04\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.6403e-04\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - ETA: 0s - loss: 7.9933e-0 - 0s 12ms/step - loss: 7.9933e-04\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.5188e-04\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.7767e-04\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2794e-04\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8899e-04\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4342e-04\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8247e-04\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3750e-04\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.7595e-04\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.0483e-04\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9360e-04\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.7553e-04\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.6115e-04\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.6056e-04\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.8284e-04\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.3904e-04\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.2781e-04\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.7414e-04\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.3664e-04\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.2519e-04\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9710e-04\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.6312e-04\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.0029e-04\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9341e-04\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5207e-04\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9499e-04\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.3991e-04\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.4416e-04\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.0748e-04\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.1097e-04\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.5321e-04\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.6138e-04\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.4328e-04\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.3986e-04\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.4202e-04\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.5468e-04\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.2560e-04\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.2868e-04\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.2144e-04\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.4937e-04\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.6592e-04\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.9813e-04\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.9854e-04\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.7358e-04\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.2523e-04\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.2524e-04\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.2323e-04\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.3333e-04\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.3236e-04\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.3530e-04\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.6802e-04\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.7282e-04\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1509e-04\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.8753e-04\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.6759e-04\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.1835e-04\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1976e-04: 0s - loss: 7.5241e-0\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9981e-04\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.3531e-04\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.7659e-04\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.3697e-04\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.0454e-04\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9026e-04\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.5480e-04\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.8895e-04\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.6217e-04\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.9601e-04\n",
      "Epoch 195/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 16ms/step - loss: 7.6011e-04\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6699e-04\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.4672e-04\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.5408e-04\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.2623e-04\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.7605e-04\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.5958e-04\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4299e-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\autots\\evaluator\\auto_model.py\u001b[0m in \u001b[0;36mTemplateWizard\u001b[1;34m(template, df_train, df_test, weights, model_count, ensemble, forecast_length, frequency, prediction_interval, no_negatives, constraint, future_regressor_train, future_regressor_forecast, holiday_country, startTimeStamps, random_seed, verbose, n_jobs, validation_round, current_generation, max_generations, model_interrupt, grouping_ids, template_cols, traceback)\u001b[0m\n\u001b[0;32m   1039\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m                 \u001b[0mtemplate_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemplate_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m             )\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\autots\\evaluator\\auto_model.py\u001b[0m in \u001b[0;36mmodel_forecast\u001b[1;34m(model_name, model_param_dict, model_transform_dict, df_train, forecast_length, frequency, prediction_interval, no_negatives, constraint, future_regressor_train, future_regressor_forecast, holiday_country, startTimeStamps, grouping_ids, random_seed, verbose, n_jobs, template_cols, horizontal_subset)\u001b[0m\n\u001b[0;32m    820\u001b[0m                     \u001b[0mtemplate_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemplate_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m                     \u001b[0mhorizontal_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhorizontal_subset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    822\u001b[0m                 )\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\autots\\evaluator\\auto_model.py\u001b[0m in \u001b[0;36mmodel_forecast\u001b[1;34m(model_name, model_param_dict, model_transform_dict, df_train, forecast_length, frequency, prediction_interval, no_negatives, constraint, future_regressor_train, future_regressor_forecast, holiday_country, startTimeStamps, grouping_ids, random_seed, verbose, n_jobs, template_cols, horizontal_subset)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[0mstartTimeStamps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstartTimeStamps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m         )\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\autots\\evaluator\\auto_model.py\u001b[0m in \u001b[0;36mModelPrediction\u001b[1;34m(df_train, forecast_length, transformation_dict, model_str, parameter_dict, frequency, prediction_interval, no_negatives, constraint, future_regressor_train, future_regressor_forecast, holiday_country, startTimeStamps, grouping_ids, random_seed, verbose, n_jobs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     )\n\u001b[1;32m--> 496\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train_transformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuture_regressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfuture_regressor_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m     df_forecast = model.predict(\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\autots\\models\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, df, future_regressor)\u001b[0m\n\u001b[0;32m   1064\u001b[0m         )\n\u001b[1;32m-> 1065\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1066\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_window\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\autots\\models\\dnn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         )\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1172\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1174\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1797\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m       \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36mreset_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m       \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3774\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3775\u001b[1;33m       \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3776\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    903\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[1;32m--> 904\u001b[1;33m           self.handle, value_tensor, name=name)\n\u001b[0m\u001b[0;32m    905\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, name)\u001b[0m\n\u001b[0;32m    140\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 141\u001b[1;33m         _ctx, \"AssignVariableOp\", name, resource, value)\n\u001b[0m\u001b[0;32m    142\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a739308e5173>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mautots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforecast_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'simple'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_data_older_than_periods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Close'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\autots\\evaluator\\auto_ts.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, df, date_col, value_col, id_col, future_regressor, weights, result_file, grouping_ids)\u001b[0m\n\u001b[0;32m    715\u001b[0m                     \u001b[0mcurrent_generation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_generation\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m                     \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m                 )\n\u001b[0;32m    719\u001b[0m                 \u001b[0mmodel_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemplate_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\autots\\evaluator\\auto_model.py\u001b[0m in \u001b[0;36mTemplateWizard\u001b[1;34m(template, df_train, df_test, weights, model_count, ensemble, forecast_length, frequency, prediction_interval, no_negatives, constraint, future_regressor_train, future_regressor_forecast, holiday_country, startTimeStamps, random_seed, verbose, n_jobs, validation_round, current_generation, max_generations, model_interrupt, grouping_ids, template_cols, traceback)\u001b[0m\n\u001b[0;32m   1175\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from autots import AutoTS\n",
    "model = AutoTS(forecast_length=10, frequency='infer', ensemble='simple', drop_data_older_than_periods=200)\n",
    "model = model.fit(data, date_col='Date', value_col='Close', id_col=None)\n",
    "\n",
    "prediction = model.predict()\n",
    "forecast = prediction.forecast\n",
    "print(\"DogeCoin Price Prediction\")\n",
    "print(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoTS' object has no attribute 'used_regressor_check'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b7d59c02b65e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\autots\\evaluator\\auto_ts.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, forecast_length, prediction_interval, future_regressor, hierarchy, just_point_forecast, verbose)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[1;31m# if the models don't need the regressor, ignore it...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mused_regressor_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m             \u001b[0mfuture_regressor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuture_regressor_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AutoTS' object has no attribute 'used_regressor_check'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
